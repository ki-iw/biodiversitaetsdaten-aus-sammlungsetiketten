{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import sys\n",
    "from lxml import etree\n",
    "from tensorflow.python.summary.summary_iterator import summary_iterator\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from kiebids.utils import crop_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Results from evaluation runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xml(file_path: str) -> dict:  # noqa\n",
    "    \"\"\"\n",
    "    Parses an XML file and extracts information about pages, text regions, and text lines.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the XML file to be parsed.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the extracted information with the following structure:\n",
    "            {\n",
    "                \"image_filename\": str,  # The filename of the image associated with the page\n",
    "                \"image_width\": str,     # The width of the image\n",
    "                \"image_height\": str,    # The height of the image\n",
    "                \"text_regions\": [       # A list of text regions\n",
    "                    {\n",
    "                        \"id\": str,           # The ID of the text region\n",
    "                        \"orientation\": str,  # The orientation of the text region\n",
    "                        \"coords\": str,       # The coordinates of the text region\n",
    "                        \"text\": str,         # The text content of the whole text region\n",
    "                        \"text_lines\": [      # A list of text lines within the text region\n",
    "                            {\n",
    "                                \"id\": str,        # The ID of the text line\n",
    "                                \"coords\": str,    # The coordinates of the text line\n",
    "                                \"baseline\": str,  # The baseline coordinates of the text line\n",
    "                                \"text\": str       # The text content of the text line\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "    \"\"\"\n",
    "\n",
    "    tree = etree.parse(file_path)  # noqa: S320  # Using `lxml` to parse untrusted data is known to be vulnerable to XML attacks\n",
    "    ns = {\"ns\": tree.getroot().nsmap.get(None, \"\")}\n",
    "\n",
    "    page = tree.find(\".//ns:Page\", namespaces=ns)\n",
    "    output = {\n",
    "        \"image_filename\": page.get(\"imageFilename\"),\n",
    "        \"image_width\": page.get(\"imageWidth\"),\n",
    "        \"image_height\": page.get(\"imageHeight\"),\n",
    "        \"text_regions\": [],\n",
    "    }\n",
    "\n",
    "    for region in page.findall(\".//ns:TextRegion\", namespaces=ns):\n",
    "        text_region = {\n",
    "            \"id\": region.get(\"id\"),\n",
    "            \"orientation\": region.get(\"orientation\"),\n",
    "            \"coords\": region.find(\".//ns:Coords\", namespaces=ns).get(\"points\"),\n",
    "            \"text\": (\n",
    "                region.findall(\".//ns:TextEquiv\", namespaces=ns)[-1]\n",
    "                .find(\".//ns:Unicode\", namespaces=ns)\n",
    "                .text\n",
    "                or \"\"\n",
    "            ),\n",
    "            \"text_lines\": [],\n",
    "        }\n",
    "\n",
    "        output[\"text_regions\"].append(text_region)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_path = \"../data/evaluation/tensorboard\"\n",
    "text_recognition_path = \"../data/debug/text_recognition\"\n",
    "preprocessed_path = \"../data/debug/preprocessing\"\n",
    "layout_analysis_path = \"../data/debug/layout_analysis\"\n",
    "\n",
    "\n",
    "class Evaluation:\n",
    "    def __init__(self, run_id):\n",
    "        self.run_id = run_id\n",
    "        self.evaluation_path = f\"{evaluation_path}/{run_id}\"\n",
    "        self.text_recognition_path = f\"{text_recognition_path}/{run_id}\"\n",
    "        self.preprocessed_path = f\"{preprocessed_path}/{run_id}\"\n",
    "        self.layout_analysis_path = f\"{layout_analysis_path}/{run_id}\"\n",
    "        self.image_mapping = self.map_image_to_index()\n",
    "        self.df, self.cer_df, self.iou_df = self.convert_tb_data()\n",
    "\n",
    "    def map_image_to_index(self):\n",
    "        files = os.listdir(self.text_recognition_path)\n",
    "        mapping = {}\n",
    "        for file in files:\n",
    "            if file.endswith(\".json\"):\n",
    "                with open(os.path.join(self.text_recognition_path, file), \"r\") as f:\n",
    "                    data = json.load(f)\n",
    "\n",
    "            if isinstance(data, dict) and \"image_index\" in data.keys():\n",
    "                mapping[data[\"image_index\"]] = file.split(\".\")[0]\n",
    "            else:\n",
    "                continue\n",
    "        return mapping\n",
    "\n",
    "    def convert_tb_data(self):\n",
    "        \"\"\"Convert local TensorBoard data into Pandas DataFrame.\n",
    "\n",
    "        Function takes the root directory path and recursively parses\n",
    "        all events data.\n",
    "        If the `sort_by` value is provided then it will use that column\n",
    "        to sort values; typically `wall_time` or `step`.\n",
    "\n",
    "        *Note* that the whole data is converted into a DataFrame.\n",
    "        Depending on the data size this might take a while. If it takes\n",
    "        too long then narrow it to some sub-directories.\n",
    "\n",
    "        Paramters:\n",
    "            root_dir: (str) path to root dir with tensorboard data.\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame with [wall_time, name, step, value] columns.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        def convert_tfevent(filepath):\n",
    "            return pd.DataFrame(\n",
    "                [\n",
    "                    parse_tfevent(e)\n",
    "                    for e in summary_iterator(filepath)\n",
    "                    if len(e.summary.value)\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        def parse_tfevent(tfevent):\n",
    "            return dict(\n",
    "                wall_time=tfevent.wall_time,\n",
    "                name=tfevent.summary.value[0].tag,\n",
    "                step=tfevent.step,\n",
    "                value=float(tfevent.summary.value[0].simple_value),\n",
    "            )\n",
    "\n",
    "        columns_order = [\"wall_time\", \"name\", \"step\", \"value\"]\n",
    "\n",
    "        out = []\n",
    "        for root, _, filenames in os.walk(self.evaluation_path):\n",
    "            for filename in filenames:\n",
    "                if \"events.out.tfevents\" not in filename:\n",
    "                    continue\n",
    "                file_full_path = os.path.join(root, filename)\n",
    "                out.append(convert_tfevent(file_full_path))\n",
    "\n",
    "        # Concatenate (and sort) all partial individual dataframes\n",
    "\n",
    "        all_df = pd.concat(out)[columns_order]\n",
    "\n",
    "        cer_df = all_df[all_df[\"name\"] == \"Text_recognition/_CER\"]\n",
    "        iou_df = all_df[all_df[\"name\"] == \"Layout_analysis/_ious\"]  # noqa: F841\n",
    "\n",
    "        all_df = all_df[\n",
    "            (all_df[\"name\"] != \"Text_recognition/_CER\")\n",
    "            & (all_df[\"name\"] != \"Layout_analysis/_ious\")\n",
    "        ]\n",
    "\n",
    "        cer_df = (\n",
    "            cer_df.reset_index()\n",
    "            .rename(\n",
    "                columns={\"value\": \"CER\", \"step\": \"image_index\", \"index\": \"bbox_index\"}\n",
    "            )\n",
    "            .drop(columns=[\"name\"])\n",
    "        )\n",
    "        iou_df = (\n",
    "            iou_df.reset_index()\n",
    "            .rename(\n",
    "                columns={\"value\": \"IOU\", \"step\": \"image_index\", \"index\": \"bbox_index\"}\n",
    "            )\n",
    "            .drop(columns=[\"name\"])\n",
    "        )\n",
    "\n",
    "        pivoted_df = (\n",
    "            pd.pivot_table(all_df, columns=\"name\", values=[\"value\"], index=[\"step\"])\n",
    "            .droplevel(0, axis=1)\n",
    "            .reset_index()\n",
    "            .rename_axis(None)\n",
    "            .rename(columns={\"step\": \"image_index\"})\n",
    "        )\n",
    "        pivoted_df.columns.name = None\n",
    "        return pivoted_df, cer_df, iou_df\n",
    "\n",
    "    def display_image(self, image_name):\n",
    "        image = Image.open(os.path.join(self.preprocessed_path, image_name + \".jpg\"))\n",
    "        display(image)\n",
    "\n",
    "    def text_recognition_result(self, image_name):\n",
    "        text_result = os.path.join(self.text_recognition_path, image_name + \".json\")\n",
    "        with open(text_result, \"r\") as f:\n",
    "            text_data = json.load(f)\n",
    "        return text_data\n",
    "\n",
    "    def read_image(self, image_name):\n",
    "        image = cv2.imread(os.path.join(self.preprocessed_path, image_name + \".jpg\"))\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The run Ids of the experiments to compare\n",
    "run_1 = Evaluation(run_id=\"20250115-174008_moondream\")\n",
    "run_2 = Evaluation(run_id=\"20250116-130831_easyocr_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(run_1.run_id)\n",
    "run_1.df.head(), run_1.cer_df.head(), run_1.iou_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(run_2.run_id)\n",
    "run_2.df.head(), run_2.cer_df.head(), run_2.iou_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Data with num ground_truth == num text predictions ({run_1.run_id}): {len(run_1.df.dropna(subset='Text_recognition/_average_CER'))} / {len(run_1.df)}\"\n",
    ")\n",
    "print(\n",
    "    f\"Data with num ground_truth == num text predictions ({run_2.run_id}): {len(run_2.df.dropna(subset='Text_recognition/_average_CER'))} / {len(run_2.df)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average IOUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_1.df.plot.hist(column=\"Layout_analysis/_average_ious\", bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_2.df.plot.hist(column=\"Layout_analysis/_average_ious\", bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_1.df.plot.hist(column=\"Text_recognition/_average_CER\", bins=100)  # , range=(0, 1))\n",
    "run_2.df.plot.hist(column=\"Text_recognition/_average_CER\", bins=100)  # , range=(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare per image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of images\n",
    "images = list(run_1.image_mapping.values())  # list(run_2.image_mapping.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image number\n",
    "i = 1\n",
    "image_name = images[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_2.display_image(image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get layout analysis results\n",
    "\n",
    "text_result_1 = run_1.text_recognition_result(image_name)\n",
    "text_result_2 = run_2.text_recognition_result(image_name)\n",
    "\n",
    "# xml = read_xml(os.path.join(results_path, images[i] + \".xml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_1.df.iloc[i][\"Text_recognition/_average_CER\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = run_1.read_image(image_name)\n",
    "\n",
    "for i, region in enumerate(text_result_1[\"regions\"]):\n",
    "    cropped_image = crop_image(image, region[\"bbox\"])\n",
    "    display(Image.fromarray(cropped_image))\n",
    "    print(run_1.run_id)\n",
    "    print(region[\"text\"])\n",
    "    print(\"------------------------\")\n",
    "    print(run_2.run_id)\n",
    "    print(text_result_2[\"regions\"][i][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruff: noqa\n",
    "def read_xml(file_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    Parses an XML file and extracts information about pages, text regions, and text lines.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the XML file to be parsed.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the extracted information with the following structure:\n",
    "            {\n",
    "                \"image_filename\": str,  # The filename of the image associated with the page\n",
    "                \"image_width\": str,     # The width of the image\n",
    "                \"image_height\": str,    # The height of the image\n",
    "                \"text_regions\": [       # A list of text regions\n",
    "                    {\n",
    "                        \"id\": str,           # The ID of the text region\n",
    "                        \"orientation\": str,  # The orientation of the text region\n",
    "                        \"coords\": str,       # The coordinates of the text region\n",
    "                        \"text\": str,         # The text content of the whole text region\n",
    "                        \"text_lines\": [      # A list of text lines within the text region\n",
    "                            {\n",
    "                                \"id\": str,        # The ID of the text line\n",
    "                                \"coords\": str,    # The coordinates of the text line\n",
    "                                \"baseline\": str,  # The baseline coordinates of the text line\n",
    "                                \"text\": str       # The text content of the text line\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "    \"\"\"\n",
    "\n",
    "    tree = etree.parse(file_path)  # noqa: S320  # Using `lxml` to parse untrusted data is known to be vulnerable to XML attacks\n",
    "    ns = {\"ns\": tree.getroot().nsmap.get(None, \"\")}\n",
    "\n",
    "    page = tree.find(\".//ns:Page\", namespaces=ns)\n",
    "    output = {\n",
    "        \"image_filename\": page.get(\"imageFilename\"),\n",
    "        \"image_width\": page.get(\"imageWidth\"),\n",
    "        \"image_height\": page.get(\"imageHeight\"),\n",
    "        \"text_regions\": [],\n",
    "    }\n",
    "\n",
    "    for region in page.findall(\".//ns:TextRegion\", namespaces=ns):\n",
    "        text_region = {\n",
    "            \"id\": region.get(\"id\"),\n",
    "            \"orientation\": region.get(\"orientation\"),\n",
    "            \"coords\": region.find(\".//ns:Coords\", namespaces=ns).get(\"points\"),\n",
    "            \"text\": (\n",
    "                region.findall(\".//ns:TextEquiv\", namespaces=ns)[-1]\n",
    "                if region.findall(\".//ns:TextEquiv\", namespaces=ns)\n",
    "                else region.find(\".//ns:Unicode\", namespaces=ns).text or \"\"\n",
    "            ),\n",
    "            \"text_lines\": [],\n",
    "        }\n",
    "\n",
    "        for line in region.findall(\".//ns:TextLine\", namespaces=ns):\n",
    "            text_region[\"text_lines\"].append(\n",
    "                {\n",
    "                    \"id\": line.get(\"id\"),\n",
    "                    \"coords\": line.find(\".//ns:Coords\", namespaces=ns).get(\"points\"),\n",
    "                    \"baseline\": line.find(\".//ns:Baseline\", namespaces=ns).get(\n",
    "                        \"points\"\n",
    "                    ),\n",
    "                    \"text\": (\n",
    "                        line.find(\".//ns:TextEquiv\", namespaces=ns)\n",
    "                        .find(\".//ns:Unicode\", namespaces=ns)\n",
    "                        .text\n",
    "                        or \"\"\n",
    "                    ),\n",
    "                }\n",
    "            )\n",
    "\n",
    "        output[\"text_regions\"].append(text_region)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "app-kiebids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
