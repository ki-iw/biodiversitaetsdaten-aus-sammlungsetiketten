{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import easyocr\n",
    "from PIL import Image\n",
    "from transformers import AutoModelForCausalLM\n",
    "import cv2\n",
    "\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "# from kiebids.parser import read_xml, get_ground_truth_text\n",
    "from kiebids.utils import crop_image, get_ground_truth_data\n",
    "from kiebids import pipeline_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_config = pipeline_config[\"text_recognition\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare text Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextRecognizer:\n",
    "    \"\"\"\n",
    "    Text Recognizer class\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model):\n",
    "        if model == \"easyocr\":\n",
    "            self.model = EasyOcr()\n",
    "        elif model == \"moondream\":\n",
    "            self.model = Moondream()\n",
    "        else:\n",
    "            print(f\"Model {model} not found. Using EasyOcr as default.\")\n",
    "            self.model = EasyOcr()\n",
    "\n",
    "    # @task(name=module)\n",
    "    # @debug_writer(debug_path, module=module)\n",
    "    # @evaluator(module=module)\n",
    "    def run(self, image: np.array, bounding_boxes: list, **kwargs):\n",
    "        \"\"\"\n",
    "        Returns text for each bounding box in image\n",
    "        Parameters:\n",
    "            image: np.array\n",
    "            bounding_boxes: list of bounding box coordinates of form [x_min,y_min,width,height]\n",
    "\n",
    "        Returns:\n",
    "            dictionary with bounding box and text\n",
    "        \"\"\"\n",
    "\n",
    "        output = []\n",
    "\n",
    "        for bounding_box in bounding_boxes:\n",
    "            cropped_image = crop_image(image, bounding_box)\n",
    "\n",
    "            text = self.model.get_text(image=cropped_image)\n",
    "\n",
    "            output.append({\"bbox\": bounding_box, \"text\": text})\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class EasyOcr:\n",
    "    \"\"\"\n",
    "    EasyOcr\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        gpu = torch.cuda.is_available()\n",
    "        self.model = easyocr.Reader([module_config.easyocr.language], gpu=gpu)\n",
    "\n",
    "    def get_text(self, image: np.array):\n",
    "        \"\"\"\n",
    "        Returns text from image.\n",
    "        \"\"\"\n",
    "        texts = self.model.readtext(\n",
    "            image,\n",
    "            decoder=module_config.easyocr.decoder,  #\n",
    "            text_threshold=module_config.easyocr.text_threshold,\n",
    "            paragraph=False,\n",
    "            detail=0,\n",
    "            y_ths=0.3,\n",
    "        )\n",
    "        print(len(texts))\n",
    "        return \"\\n\".join(texts) if texts else \"\"\n",
    "\n",
    "\n",
    "class Moondream:\n",
    "    \"\"\"\n",
    "    Moondream 1.9B 2025-01-09 Release\n",
    "    Huggingface: https://huggingface.co/vikhyatk/moondream2\n",
    "    Documentation: https://docs.moondream.ai/\n",
    "    Blog post: https://moondream.ai/blog/introducing-a-new-moondream-1-9b-and-gpu-support\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        gpu = torch.cuda.is_available()\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            module_config.moondream.name,\n",
    "            revision=module_config.moondream.revision,\n",
    "            trust_remote_code=module_config.moondream.trust_remote_code,\n",
    "            device_map={\"\": \"cuda\"} if gpu else None,\n",
    "        )\n",
    "        self.prompt = module_config.moondream.prompt\n",
    "\n",
    "    def get_text(self, image: np.array):\n",
    "        pil_image = Image.fromarray(image)\n",
    "        text = self.model.query(pil_image, self.prompt)[\"answer\"]\n",
    "        return self.clean_text(text)\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        \"\"\"\n",
    "        Moondream specific text cleaning.\n",
    "        \"\"\"\n",
    "        return text.replace(\"\\n\\n\", \"\\n\").strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to folder with cropped images (after layout analysis step)\n",
    "image_path = \"/home/jupyter-lova/app-kiebids-2/data/debug/layout_analysis/20250116-135623_easyocr_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "easyocr_model = TextRecognizer(\"easyocr\")\n",
    "\n",
    "moondream_model = TextRecognizer(\"moondream\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = os.listdir(image_path)\n",
    "\n",
    "image_number = 9\n",
    "\n",
    "image = cv2.imread(os.path.join(image_path, images[image_number]))\n",
    "\n",
    "# get the image name to get the ground truth data\n",
    "image_name = images[image_number].split(\".\")[0][:-2] + \".jpg\"\n",
    "print(image_name)\n",
    "ground_truth_data = get_ground_truth_data(image_name)\n",
    "\n",
    "if ground_truth_data:\n",
    "    texts = [region[\"text\"] for region in ground_truth_data[\"text_regions\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image.fromarray(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_redone = [t.replace(\"\\r\\n\", \"\\n\") for t in texts]\n",
    "text_redone[3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "app-kiebids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
